{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "994fa2c4-fa9c-4823-b65c-5eb0201feaaf",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation\n",
    "This notebook covers the implimentation of a Retrieval-Augemented Generation framework with a pre-trained LLM and has been largely adopted from James Briggs work linked in the resources. I have contributed a few explainers as well as PDF document intergration pipeline using AWS Textract in the interest of expanding potential data sources for the RAG knowledge library (otherwise known as a 'content store' or 'data store'). \n",
    "\n",
    "Below is the project outline involving both .csv ingest as well as .pdf ingest for the knowledge library. A quick video primer on the basics of the Retrieval-Augmented Generation framework can be found under \"What is Retrieval-Augmented Generation (RAG)?\" in the resources.\n",
    "\n",
    "<img src=\"./images/project_overview.png\" width=\"700\" />\n",
    "\n",
    "#### Topics Covered:\n",
    "- Retrieval-Augmented Generation (RAG) Basics\n",
    "- AWS Hugging Face SDK and deploying pre-trained models\n",
    "- AWS Textract for PDF Optical Character Recognition (OCR)\n",
    "- Pinecone Vector Database - Creating, populating and Querying Indexes\n",
    "\n",
    "#### Resources:\n",
    "- James Briggs Hugging Face LLMs with SageMaker + RAG with Pinecone - https://github.com/pinecone-io/examples/blob/master/learn/generation/aws/sagemaker/sagemaker-huggingface-rag.ipynb\n",
    "- What is Retrieval-Augmented Generation (RAG)?: https://www.youtube.com/watch?v=T-D1OfcDW1M\n",
    "- Pinecone Database: https://www.pinecone.io\n",
    "- SageMaker Hugging Face Documentation - https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html#hugging-face-model\n",
    "- AWS Textract: https://aws.amazon.com/textract/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f24ad8-9c1a-44c7-b931-c2f2196d2e66",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:10px; font-size:20px\">\n",
    "Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4e30f328-e878-4f15-b009-243fc8035a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU \\\n",
    "    sagemaker==2.173.0 \\\n",
    "    pinecone-client==2.2.1 \\\n",
    "    ipywidgets==7.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f43ff-9c2d-47af-82d7-ef9282c06b36",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:10px; font-size:20px\">\n",
    "ðŸ¤— HF LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81429c52-7826-4930-a168-155eb31787b9",
   "metadata": {},
   "source": [
    "The SageMaker HuggingFace SDK allows you to deploy models from 2 different sources:\n",
    "- Trained models stored in s3\n",
    "- Pre-trained models from the HuggingFace Hub\n",
    "\n",
    "We will be deploying a pre-trained model from the HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ae04bcc5-13a2-48e5-90a9-f283184249b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import (\n",
    "    HuggingFaceModel,\n",
    "    get_huggingface_llm_image_uri\n",
    ")\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "hub_config = {\n",
    "    'HF_MODEL_ID':'google/flan-t5-xl', # model_id from hf.co/models\n",
    "    'HF_TASK':'text-generation' # NLP task you want to use for predictions\n",
    "}\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"0.8.2\"\n",
    ")\n",
    "\n",
    "# Create Huggingface Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    env=hub_config,\n",
    "    role=role, # iam role with permissions to create an Endpoint\n",
    "    image_uri=llm_image\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09adca4-a2a6-4746-a63c-343054317902",
   "metadata": {},
   "source": [
    "Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "62411aa3-47e9-4e37-81f4-21324e5d2f07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "llm = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.4xlarge\",\n",
    "    endpoint_name=\"flan-t5-demo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126b818f-d06d-439a-ad59-6cf1f6f7790c",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:10px; font-size:20px\">\n",
    "Context Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659b457c-680b-4db6-b5d9-01d5bd9b41ae",
   "metadata": {},
   "source": [
    "<div style=\"background-color:darkblue; color:white; padding:1px; font-size:20px\">\n",
    "Questioning the Model Without Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d39d27fd-59a6-43c3-a285-486ee62aa7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'SageMaker and SageMaker XL.'}]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Which instances can I use with Managed Spot Training in SageMaker?\"\n",
    "\n",
    "out = llm.predict({\"inputs\": question})\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c4489-7241-4f0c-a0bf-832d501f5ec5",
   "metadata": {},
   "source": [
    "<div style=\"background-color:darkblue; color:white; padding:1px; font-size:20px\">\n",
    "Questioning the Model With Manually Added Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ba2f680e-ce2d-4d74-8bdc-11c8bfe5a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"Managed Spot Training can be used with all instances\n",
    "supported in Amazon SageMaker. Managed Spot Training is supported\n",
    "in all AWS Regions where Amazon SageMaker is currently available.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "27d37afd-57a2-41f3-a08f-2f2a0a309d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Input]: Which instances can I use with Managed Spot Training in SageMaker?\n",
      "[Output]: all instances supported in Amazon SageMaker\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"Answer the following QUESTION based on the CONTEXT\n",
    "given. If you do not know the answer and the CONTEXT doesn't\n",
    "contain the answer truthfully say \"I don't know\".\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "\n",
    "text_input = prompt_template.replace(\"{context}\", context).replace(\"{question}\", question)\n",
    "\n",
    "out = llm.predict({\"inputs\": text_input})\n",
    "generated_text = out[0][\"generated_text\"]\n",
    "print(f\"[Input]: {question}\\n[Output]: {generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77eece5-f7fe-4b0a-b732-a7d878754a33",
   "metadata": {},
   "source": [
    "<div style=\"background-color:darkblue; color:white; padding:1px; font-size:20px\">\n",
    "Asking Unanswerable Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acefa049-f718-48e8-acf2-260345142095",
   "metadata": {},
   "source": [
    "Notice how the mere addition of:\n",
    "\n",
    "'If you do not know the answer and the CONTEXT doesn't contain the answer truthfully say \"I don't know\".' \n",
    "\n",
    "In the prompt template can gaurd against hallucination in the model. We will test this behavior out with the query below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8d20837b-8fb2-4408-a963-b0d5390c0943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Input]: What color is my desk?\n",
      "[Output]: I don't know\n"
     ]
    }
   ],
   "source": [
    "unanswerable_question = \"What color is my desk?\"\n",
    "\n",
    "text_input = prompt_template.replace(\"{context}\", context).replace(\"{question}\", unanswerable_question)\n",
    "\n",
    "out = llm.predict({\"inputs\": text_input})\n",
    "generated_text = out[0][\"generated_text\"]\n",
    "print(f\"[Input]: {unanswerable_question}\\n[Output]: {generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ee1b67-5e03-4caa-9658-e801ba11ba56",
   "metadata": {},
   "source": [
    "This of course is the desired behavior which we will test for again at the end of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fa3975-302d-4a99-9589-1b72daa8ccb3",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:10px; font-size:20px\">\n",
    "RAG-Based Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21f2e02-f6b2-4a22-94ab-3ddd1699fddb",
   "metadata": {},
   "source": [
    "Deploy Embedding Model from HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ed3c7692-129b-4b30-891f-f7c23491368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_config = {\n",
    "    'HF_MODEL_ID': 'sentence-transformers/all-MiniLM-L6-v2', # model_id from hf.co/models\n",
    "    'HF_TASK': 'feature-extraction'\n",
    "}\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    env=hub_config,\n",
    "    role=role,\n",
    "    transformers_version=\"4.6\", # transformers version used\n",
    "    pytorch_version=\"1.7\", # pytorch version used\n",
    "    py_version=\"py36\", # python version of the DLC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "40266406-9c58-465c-811e-782a9e2838e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "encoder = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t2.large\",\n",
    "    endpoint_name=\"minilm-demo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "669a35e3-15e2-4fe4-9eb5-ca3fc96b9eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = encoder.predict({\"inputs\": [\"some text here\", \"some more text goes here too\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8eccec3f-5814-40e6-bffe-4c4ca70415d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "8 8\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "print(len(out))\n",
    "print(len(out[0]), len(out[1]))\n",
    "print(len(out[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a1415eab-4f5e-4ab6-972c-2e141a671a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 384)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = np.mean(np.array(out), axis=1)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fed5cc8b-e9ce-43ed-bba3-33705064f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def embed_docs(docs: List[str]) -> List[List[float]]:\n",
    "    out = encoder.predict({'inputs': docs})\n",
    "    embeddings = np.mean(np.array(out), axis=1)\n",
    "    return embeddings.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87921947-0a3c-491f-8a65-4c1ea64f1a62",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:10px; font-size:20px\">\n",
    "Knowledge Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941200cb-be16-4442-b44e-81bb38af8798",
   "metadata": {},
   "source": [
    "<div style=\"background-color:darkblue; color:white; padding:1px; font-size:20px\">\n",
    "AWS FAQ (.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148207ad-d1a7-4fa3-beb0-8715f3bf8edb",
   "metadata": {},
   "source": [
    "The AWS SageMaker FAQ dataset is a two-column, question & answer .csv file stored on s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "aa40305b-318c-4361-a74f-6a25a591a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = f\"s3://jumpstart-cache-prod-us-east-2/training-datasets/Amazon_SageMaker_FAQs/Amazon_SageMaker_FAQs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2258b9c0-2b3d-4602-a2fc-396a4e0def7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://jumpstart-cache-prod-us-east-2/training-datasets/Amazon_SageMaker_FAQs/Amazon_SageMaker_FAQs.csv to ./Amazon_SageMaker_FAQs.csv\n"
     ]
    }
   ],
   "source": [
    "# Downloading the Database\n",
    "!aws s3 cp $s3_path Amazon_SageMaker_FAQs.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "81bfaa61-d57a-4b82-b6f7-e80f64c4b8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Amazon SageMaker?</td>\n",
       "      <td>Amazon SageMaker is a fully managed service to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In which Regions is Amazon SageMaker available...</td>\n",
       "      <td>For a list of the supported Amazon SageMaker A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the service availability of Amazon Sag...</td>\n",
       "      <td>Amazon SageMaker is designed for high availabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does Amazon SageMaker secure my code?</td>\n",
       "      <td>Amazon SageMaker stores code in ML storage vol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What security measures does Amazon SageMaker h...</td>\n",
       "      <td>Amazon SageMaker ensures that ML model artifac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0                          What is Amazon SageMaker?   \n",
       "1  In which Regions is Amazon SageMaker available...   \n",
       "2  What is the service availability of Amazon Sag...   \n",
       "3          How does Amazon SageMaker secure my code?   \n",
       "4  What security measures does Amazon SageMaker h...   \n",
       "\n",
       "                                              Answer  \n",
       "0  Amazon SageMaker is a fully managed service to...  \n",
       "1  For a list of the supported Amazon SageMaker A...  \n",
       "2  Amazon SageMaker is designed for high availabi...  \n",
       "3  Amazon SageMaker stores code in ML storage vol...  \n",
       "4  Amazon SageMaker ensures that ML model artifac...  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_knowledge = pd.read_csv(\"Amazon_SageMaker_FAQs.csv\", header=None, names=[\"Question\", \"Answer\"])\n",
    "df_knowledge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e8702f2a-fe86-4732-a061-1985dd480746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker is a fully managed service to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For a list of the supported Amazon SageMaker A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon SageMaker is designed for high availabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon SageMaker stores code in ML storage vol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon SageMaker ensures that ML model artifac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Answer\n",
       "0  Amazon SageMaker is a fully managed service to...\n",
       "1  For a list of the supported Amazon SageMaker A...\n",
       "2  Amazon SageMaker is designed for high availabi...\n",
       "3  Amazon SageMaker stores code in ML storage vol...\n",
       "4  Amazon SageMaker ensures that ML model artifac..."
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_knowledge.drop([\"Question\"], axis=1, inplace=True)\n",
    "df_knowledge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e4c3bf-b00e-4d36-abf8-b1fe94943ec6",
   "metadata": {},
   "source": [
    "<div style=\"background-color:darkblue; color:white; padding:1px; font-size:20px\">\n",
    "PDF Integration (AWS Textract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dd32308f-25da-4213-8e79-72db49a9b6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install amazon-textract-caller --upgrade -q\n",
    "!python -m pip install amazon-textract-response-parser --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "145a93ac-6293-4dc5-9848-b1c410f8c4c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e056fbb7-9af5-40cd-801f-388b3925ea4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mySession = boto3.session.Session()\n",
    "awsRegion = mySession.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b3e56bd4-fd78-4655-94eb-126ce01e1c35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws-workshops-us-east-1\n"
     ]
    }
   ],
   "source": [
    "s3BucketName = \"aws-workshops-\" + awsRegion\n",
    "print(s3BucketName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "30a5c0d4-72c0-4bd7-937c-78bc657a5dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Amazon S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Amazon Textract client\n",
    "textract = boto3.client('textract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7f88f342-859e-452d-9f56-41cf3ef65701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Document\n",
    "documentName = \"textract-samples/Amazon-Textract-Pdf.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6f59f8-7028-4b52-8fcc-6b1783f2d032",
   "metadata": {},
   "source": [
    "Below are a few AWS helper functions for processing PDF's with AWS textract. Addtional information can be found: https://github.com/aws-samples/amazon-textract-code-samples/blob/master/python/Textract.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "78170501-7d26-41e8-af3f-2131cf193154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def startJob(s3BucketName, objectName):\n",
    "    response = None\n",
    "    response = textract.start_document_text_detection(\n",
    "    DocumentLocation={\n",
    "        'S3Object': {\n",
    "            'Bucket': s3BucketName,\n",
    "            'Name': objectName\n",
    "        }\n",
    "    })\n",
    "\n",
    "    return response[\"JobId\"]\n",
    "\n",
    "def isJobComplete(jobId):\n",
    "    response = textract.get_document_text_detection(JobId=jobId)\n",
    "    status = response[\"JobStatus\"]\n",
    "    print(\"Job status: {}\".format(status))\n",
    "\n",
    "    while(status == \"IN_PROGRESS\"):\n",
    "        time.sleep(5)\n",
    "        response = textract.get_document_text_detection(JobId=jobId)\n",
    "        status = response[\"JobStatus\"]\n",
    "        print(\"Job status: {}\".format(status))\n",
    "\n",
    "    return status\n",
    "\n",
    "def getJobResults(jobId):\n",
    "\n",
    "    pages = []\n",
    "    response = textract.get_document_text_detection(JobId=jobId)\n",
    "        \n",
    "    pages.append(response)\n",
    "    print(\"Resultset page recieved: {}\".format(len(pages)))\n",
    "    nextToken = None\n",
    "    if('NextToken' in response):\n",
    "        nextToken = response['NextToken']\n",
    "\n",
    "    while(nextToken):\n",
    "        response = textract.get_document_text_detection(JobId=jobId, NextToken=nextToken)\n",
    "\n",
    "        pages.append(response)\n",
    "        print(\"Resultset page recieved: {}\".format(len(pages)))\n",
    "        nextToken = None\n",
    "        if('NextToken' in response):\n",
    "            nextToken = response['NextToken']\n",
    "\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "599709a3-5d26-45c6-a1c1-ab43ba60325e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started job with id: 19227996172071c389f2660e8433ed7540473e9dcdeeeafd7ddd6f6281f96b01\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: SUCCEEDED\n",
      "Resultset page recieved: 1\n",
      "\u001b[94mAmazon Textract\u001b[0m\n",
      "\u001b[94mAmazon Textract is a service that automatically extracts text and data from scanned\u001b[0m\n",
      "\u001b[94mdocuments. Amazon Textract goes beyond simple optical character recognition (OCR) to\u001b[0m\n",
      "\u001b[94malso identify the contents of fields in forms and information stored in tables.\u001b[0m\n",
      "\u001b[94mMany companies today extract data from documents and forms through manual data\u001b[0m\n",
      "\u001b[94mentry that's slow and expensive or through simple optical character recognition (OCR)\u001b[0m\n",
      "\u001b[94msoftware that is difficult to customize. Rules and workflows for each document and form\u001b[0m\n",
      "\u001b[94moften need to be hard-coded and updated with each change to the form or when dealing\u001b[0m\n",
      "\u001b[94mwith multiple forms. If the form deviates from the rules, the output is often scrambled\u001b[0m\n",
      "\u001b[94mand unusable.\u001b[0m\n",
      "\u001b[94mAmazon Textract overcomes these challenges by using machine learning to instantly\u001b[0m\n",
      "\u001b[94m\"read\" virtually any type of document to accurately extract text and data without the\u001b[0m\n",
      "\u001b[94mneed for any manual effort or custom code. With Textract you can quickly automate\u001b[0m\n",
      "\u001b[94mdocument workflows, enabling you to process millions of document pages in hours.\u001b[0m\n",
      "\u001b[94mOnce the information is captured, you can take action on it within your business\u001b[0m\n",
      "\u001b[94mapplications to initiate next steps for a loan application or medical claims processing.\u001b[0m\n",
      "\u001b[94mAdditionally, you can create smart search indexes, build automated approval workflows,\u001b[0m\n",
      "\u001b[94mand better maintain compliance with document archival rules by flagging data that may\u001b[0m\n",
      "\u001b[94mrequire redaction.\u001b[0m\n",
      "\u001b[94mUse cases\u001b[0m\n",
      "\u001b[94mCreate smart search indexes\u001b[0m\n",
      "\u001b[94mExtract structured data from documents and create a smart index using Amazon Elasticsearch\u001b[0m\n",
      "\u001b[94mService to allow you to search through millions of financial statements quickly. For example, a\u001b[0m\n",
      "\u001b[94mmortgage company could use Amazon Textract to process millions of scanned loan applications in\u001b[0m\n",
      "\u001b[94ma matter of hours and have the extracted data indexed in Amazon Elasticsearch. This would allow\u001b[0m\n",
      "\u001b[94mthem to create search experiences like \"search for loan applications where applicant name is John\u001b[0m\n",
      "\u001b[94mDoe,\" or \"search contracts where the interest rate is 2 percent.\"\u001b[0m\n",
      "\u001b[94mBuild automated document processing workflows\u001b[0m\n",
      "\u001b[94mAmazon Textract can provide the inputs required to automatically process forms without human\u001b[0m\n",
      "\u001b[94mintervention. For example, a bank could write code to read PDFs of loan applications. The\u001b[0m\n",
      "\u001b[94minformation contained in the document could be used to initiate all of the necessary background\u001b[0m\n",
      "\u001b[94mand credit checks to approve the loan so that customers can get instant results of their application\u001b[0m\n",
      "\u001b[94mrather than having to wait several days for manual review and validation.\u001b[0m\n",
      "\u001b[94mMaintain compliance in document archives\u001b[0m\n",
      "\u001b[94mBecause Amazon Textract identifies data types and form labels automatically, it's easy to maintain\u001b[0m\n",
      "\u001b[94mcompliance with information controls. For example, an insurer could use Amazon Textract to feed\u001b[0m\n",
      "\u001b[94ma workflow that automatically redacts personally identifiable information (PII) for their review\u001b[0m\n",
      "\u001b[94mbefore archiving claim forms by automatically recognizing the important key-value pairs that\u001b[0m\n",
      "\u001b[94mrequire protection.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Invoke textract API\n",
    "jobId = startJob(s3BucketName, documentName)\n",
    "print(\"Started job with id: {}\".format(jobId))\n",
    "if(isJobComplete(jobId)):\n",
    "    response = getJobResults(jobId)\n",
    "\n",
    "#print(response)\n",
    "\n",
    "# Print detected text\n",
    "for resultPage in response:\n",
    "    for item in resultPage[\"Blocks\"]:\n",
    "        if item[\"BlockType\"] == \"LINE\":\n",
    "            print ('\\033[94m' +  item[\"Text\"] + '\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e45d4a4-fe48-4383-809e-33516395ea3f",
   "metadata": {},
   "source": [
    "The response will be a JSON containing our desired text as well as metadata and additional information. In order to feed the text into the embedding model, we will need to extract it from the JSON and perform some simple processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "dd5aa329-17b0-42f4-ad1a-d43a634925d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_text_from_json(data):\n",
    "    try:\n",
    "        text_lines = []\n",
    "        for block in data['Blocks']:\n",
    "            if block['BlockType'] == 'LINE':\n",
    "                text_lines.append(block['Text'])\n",
    "        return text_lines\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9607149c-7b0b-4b15-b7dd-8252464a4d36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extracted_text = extract_text_from_json(response[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3026f9-eab7-487a-b49b-0ee41801a788",
   "metadata": {},
   "source": [
    "Perfectly parsing the OCR response of AWS Textract can be an involved process depending on the PDF. For example, this document contains paragraph headers whose formatting was not explicitly translated through the OCR process. This results in chunks of text that are neither separated with punctuation, nor should they be included with neighboring sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b723b0cb-6192-464c-9642-525d378a44fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amazon Textract',\n",
       " 'Amazon Textract is a service that automatically extracts text and data from scanned',\n",
       " 'documents. Amazon Textract goes beyond simple optical character recognition (OCR) to',\n",
       " 'also identify the contents of fields in forms and information stored in tables.',\n",
       " 'Many companies today extract data from documents and forms through manual data',\n",
       " \"entry that's slow and expensive or through simple optical character recognition (OCR)\",\n",
       " 'software that is difficult to customize. Rules and workflows for each document and form',\n",
       " 'often need to be hard-coded and updated with each change to the form or when dealing',\n",
       " 'with multiple forms. If the form deviates from the rules, the output is often scrambled',\n",
       " 'and unusable.',\n",
       " 'Amazon Textract overcomes these challenges by using machine learning to instantly',\n",
       " '\"read\" virtually any type of document to accurately extract text and data without the',\n",
       " 'need for any manual effort or custom code. With Textract you can quickly automate',\n",
       " 'document workflows, enabling you to process millions of document pages in hours.',\n",
       " 'Once the information is captured, you can take action on it within your business',\n",
       " 'applications to initiate next steps for a loan application or medical claims processing.',\n",
       " 'Additionally, you can create smart search indexes, build automated approval workflows,',\n",
       " 'and better maintain compliance with document archival rules by flagging data that may',\n",
       " 'require redaction.',\n",
       " 'Use cases',\n",
       " 'Create smart search indexes',\n",
       " 'Extract structured data from documents and create a smart index using Amazon Elasticsearch',\n",
       " 'Service to allow you to search through millions of financial statements quickly. For example, a',\n",
       " 'mortgage company could use Amazon Textract to process millions of scanned loan applications in',\n",
       " 'a matter of hours and have the extracted data indexed in Amazon Elasticsearch. This would allow',\n",
       " 'them to create search experiences like \"search for loan applications where applicant name is John',\n",
       " 'Doe,\" or \"search contracts where the interest rate is 2 percent.\"',\n",
       " 'Build automated document processing workflows',\n",
       " 'Amazon Textract can provide the inputs required to automatically process forms without human',\n",
       " 'intervention. For example, a bank could write code to read PDFs of loan applications. The',\n",
       " 'information contained in the document could be used to initiate all of the necessary background',\n",
       " 'and credit checks to approve the loan so that customers can get instant results of their application',\n",
       " 'rather than having to wait several days for manual review and validation.',\n",
       " 'Maintain compliance in document archives',\n",
       " \"Because Amazon Textract identifies data types and form labels automatically, it's easy to maintain\",\n",
       " 'compliance with information controls. For example, an insurer could use Amazon Textract to feed',\n",
       " 'a workflow that automatically redacts personally identifiable information (PII) for their review',\n",
       " 'before archiving claim forms by automatically recognizing the important key-value pairs that',\n",
       " 'require protection.']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d87d35-11b5-4fb0-a75e-2846fd62dbaa",
   "metadata": {},
   "source": [
    "As noted, the current parsing is not flawless, but should be sufficient for our retrieved context as many LLMs can handle more extreme redundancies and syntax errors than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f33d2567-c77f-47db-bdaa-4c82af718797",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon Textract Amazon Textract is a service t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon Textract goes beyond simple optical cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Many companies today extract data from documen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rules and workflows for each document and form...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If the form deviates from the rules, the outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazon Textract overcomes these challenges by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>With Textract you can quickly automate documen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Once the information is captured, you can take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Additionally, you can create smart search inde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Use cases Create smart search indexes Extract ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>For example, a mortgage company could use Amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This would allow them to create search experie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\" Build automated document processing workflow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>For example, a bank could write code to read P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The information contained in the document coul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Maintain compliance in document archives Becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>For example, an insurer could use Amazon Textr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Answer\n",
       "0   Amazon Textract Amazon Textract is a service t...\n",
       "1   Amazon Textract goes beyond simple optical cha...\n",
       "2   Many companies today extract data from documen...\n",
       "3   Rules and workflows for each document and form...\n",
       "4   If the form deviates from the rules, the outpu...\n",
       "5   Amazon Textract overcomes these challenges by ...\n",
       "6   With Textract you can quickly automate documen...\n",
       "7   Once the information is captured, you can take...\n",
       "8   Additionally, you can create smart search inde...\n",
       "9   Use cases Create smart search indexes Extract ...\n",
       "10  For example, a mortgage company could use Amaz...\n",
       "11  This would allow them to create search experie...\n",
       "12  \" Build automated document processing workflow...\n",
       "13  For example, a bank could write code to read P...\n",
       "14  The information contained in the document coul...\n",
       "15  Maintain compliance in document archives Becau...\n",
       "16  For example, an insurer could use Amazon Textr..."
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Concatenate the texts by their separators\n",
    "full_text = \" \".join(extracted_text)\n",
    "\n",
    "# Split the full text by sentence-ending punctuation to create individual sentences\n",
    "sentences = [sentence.strip() for sentence in full_text.split('.') if sentence]\n",
    "\n",
    "# Create a pandas dataframe with the column 'sentence' containing each sentence\n",
    "pdf_df = pd.DataFrame(sentences, columns=['Answer'])\n",
    "pdf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a65be6af-6b5d-44a8-a54b-55d6a00a065a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17 entries, 0 to 16\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  17 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 264.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_sentences.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee3c25-4b36-47dd-b2dc-85da32a8e2d6",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:10px; font-size:20px\">\n",
    "Pinecone Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96369ab7-44ca-4edb-9db7-f416ecd38873",
   "metadata": {},
   "source": [
    "<div style=\"background-color:darkblue; color:white; padding:1px; font-size:20px\">\n",
    "Initializing Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbc9f37-3ec0-47f8-8209-0d377c8b95b8",
   "metadata": {},
   "source": [
    "You will need to make a free Pinecone account at: https://www.pinecone.io\n",
    "\n",
    "Copy/paste your Pinecone account API key into \"YOUR_API_KEY\" and the environment in \"YOUR_ENV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "13725d06-ff34-4bb4-a97f-dfb1bb47c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "import os\n",
    "\n",
    "# add Pinecone API key from app.pinecone.io\n",
    "api_key = os.environ.get(\"PINECONE_API_KEY\") or \"YOUR_API_KEY\"\n",
    "# set Pinecone environment - find next to API key in console\n",
    "env = os.environ.get(\"PINECONE_ENVIRONMENT\") or \"YOUR_ENV\"\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=api_key,\n",
    "    environment=env\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a38b13f0-e974-432b-881c-adeb7dd4f11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aws-rag-knowledge-base']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f2d207c9-916a-4088-a41e-595e8dd7211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = 'aws-rag-knowledge-base'\n",
    "\n",
    "while not pinecone.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "91041533-0482-47d7-ba6b-cb3167f20add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aws-rag-knowledge-base']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de6878a-0f8d-4930-8287-f1c8e60ba007",
   "metadata": {},
   "source": [
    "<div style=\"background-color:darkblue; color:white; padding:1px; font-size:20px\">\n",
    "Upserting Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "629ad21e-317f-488f-bb24-9cdbe3bf1ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77/77 [00:26<00:00,  2.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = 2  # can increase but needs larger instance size otherwise instance runs out of memory\n",
    "vector_limit = 1000\n",
    "\n",
    "answers = df_knowledge[:vector_limit]\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "for i in tqdm(range(0, len(answers), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(answers))\n",
    "    # create IDs batch\n",
    "    ids = [str(x) for x in range(i, i_end)]\n",
    "    # create metadata batch\n",
    "    metadatas = [{'text': text} for text in answers[\"Answer\"][i:i_end]]\n",
    "    # create embeddings\n",
    "    texts = answers[\"Answer\"][i:i_end].tolist()\n",
    "    embeddings = embed_docs(texts)\n",
    "    # create records list for upsert\n",
    "    records = zip(ids, embeddings, metadatas)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e3532-cac3-4f6b-9e0f-e7e4ac36cb06",
   "metadata": {
    "tags": []
   },
   "source": [
    "Lets get a quick look at our index. The following code returns 4 metrics:\n",
    "- `dimesnion`: The dimensionality of the vectors stored in the index\n",
    "- `index_fullness`: A value between 1-0 indicating how much of the index is being used. 0.00154 = 0.154%\n",
    "- `namespaces`: Namespaces are a way to segment/categorize stored vectors in the index. There is currently the empty '' default namespace with 154 records in it\n",
    "- `total_vector_count`: Total # of stored vectors in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a9687361-3099-43ee-9fd3-934f8ed5192f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.00171,\n",
       " 'namespaces': {'': {'vector_count': 171}},\n",
       " 'total_vector_count': 171}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of records in the index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2aacb2-8a5e-41f2-8693-0d2c13346733",
   "metadata": {},
   "source": [
    "Now we will do the same thing for the PDF df we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6ed61bf0-fbe0-487d-a139-f24eb8c9a736",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  6.24it/s]\n"
     ]
    }
   ],
   "source": [
    "answers = pdf_df[:vector_limit]\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "for i in tqdm(range(0, len(answers), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(answers))\n",
    "    # create IDs batch\n",
    "    ids = [str(x) + 'pdf' for x in range(i, i_end)]\n",
    "    # create metadata batch\n",
    "    metadatas = [{'text': text} for text in answers[\"Answer\"][i:i_end]]\n",
    "    # create embeddings\n",
    "    texts = answers[\"Answer\"][i:i_end].tolist()\n",
    "    embeddings = embed_docs(texts)\n",
    "    # create records list for upsert\n",
    "    records = zip(ids, embeddings, metadatas)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce6ab3-3b9e-4daf-ab9d-3961226a526e",
   "metadata": {},
   "source": [
    "If the upsertion was successful, we should now have 171 records in the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1eefd58c-0600-4e5d-acfa-a830ce57a514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.00171,\n",
       " 'namespaces': {'': {'vector_count': 171}},\n",
       " 'total_vector_count': 171}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of records in the index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d96095-bc65-41f6-af8b-7f94b79418fe",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:10px; font-size:20px\">\n",
    "Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7dbea-9bb1-4b3a-bf5b-6fd1af5b1c54",
   "metadata": {},
   "source": [
    "<div style=\"background-color:darkblue; color:white; padding:1px; font-size:20px\">\n",
    "Retrieving Context From Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e20f9210-0182-4b69-a2b3-9aba041f70d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which instances can I use with Managed Spot Training in SageMaker?'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "371db98d-1eaa-4eda-85ba-585bb41dd0b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '90',\n",
       "              'metadata': {'text': 'Managed Spot Training can be used with all '\n",
       "                                   'instances supported in Amazon '\n",
       "                                   'SageMaker.\\r\\n'},\n",
       "              'score': 0.881003916,\n",
       "              'values': []},\n",
       "             {'id': '91',\n",
       "              'metadata': {'text': 'Managed Spot Training is supported in all '\n",
       "                                   'AWS Regions where Amazon SageMaker is '\n",
       "                                   'currently available.\\r\\n'},\n",
       "              'score': 0.799601316,\n",
       "              'values': []},\n",
       "             {'id': '85',\n",
       "              'metadata': {'text': 'You enable the Managed Spot Training '\n",
       "                                   'option when submitting your training jobs '\n",
       "                                   'and you also specify how long you want to '\n",
       "                                   'wait for Spot capacity. Amazon SageMaker '\n",
       "                                   'will then use Amazon EC2 Spot instances to '\n",
       "                                   'run your job and manages the Spot '\n",
       "                                   'capacity. You have full visibility into '\n",
       "                                   'the status of your training jobs, both '\n",
       "                                   'while they are running and while they are '\n",
       "                                   'waiting for capacity.'},\n",
       "              'score': 0.733746827,\n",
       "              'values': []},\n",
       "             {'id': '84',\n",
       "              'metadata': {'text': 'Managed Spot Training with Amazon '\n",
       "                                   'SageMaker lets you train your ML models '\n",
       "                                   'using Amazon EC2 Spot instances, while '\n",
       "                                   'reducing the cost of training your models '\n",
       "                                   'by up to 90%.'},\n",
       "              'score': 0.721574843,\n",
       "              'values': []},\n",
       "             {'id': '87',\n",
       "              'metadata': {'text': 'Managed Spot Training uses Amazon EC2 Spot '\n",
       "                                   'instances for training, and these '\n",
       "                                   'instances can be pre-empted when AWS needs '\n",
       "                                   'capacity. As a result, Managed Spot '\n",
       "                                   'Training jobs can run in small increments '\n",
       "                                   'as and when capacity becomes available. '\n",
       "                                   'The training jobs need not be restarted '\n",
       "                                   'from scratch when there is an '\n",
       "                                   'interruption, as Amazon SageMaker can '\n",
       "                                   'resume the training jobs using the latest '\n",
       "                                   'model checkpoint. The built-in frameworks '\n",
       "                                   'and the built-in computer vision '\n",
       "                                   'algorithms with SageMaker enable periodic '\n",
       "                                   'checkpoints, and you can enable '\n",
       "                                   'checkpoints with custom models.'},\n",
       "              'score': 0.721429288,\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract embeddings for the questions\n",
    "query_vec = embed_docs(question)[0]\n",
    "\n",
    "# query pinecone\n",
    "res = index.query(query_vec, top_k=5, include_metadata=True)\n",
    "\n",
    "# show the results\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "176da8a6-ba6b-4feb-a48f-f38922a6e904",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build list from text fields of database response \n",
    "contexts = [match.metadata['text'] for match in res.matches]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10690f71-0255-4d46-8cf0-2ff14be0e25b",
   "metadata": {},
   "source": [
    "The block below concatenates as many returned texts as possible while not exceeding the character threshold (1000 characters). Two things to note:\n",
    "- This values completed sentences over maximizing the character limit for overall context coherence.\n",
    "- `max_selection_len` is a self-imposed limit to optimize the LLM response (with regard to the passed context). This is based on the general observation in LLM's that passing large context lengths results in the middle of the context being overlooked, essentially passing more context information than the model can handle which negatively impacts performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "82136668-36fa-4ce5-8843-759699c611ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_section_len = 1000\n",
    "separator = \"\\n\"\n",
    "\n",
    "def construct_context(contexts: List[str]) -> str:\n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 0\n",
    "\n",
    "    for text in contexts:\n",
    "        text = text.strip()\n",
    "        # Add contexts until we run out of space.\n",
    "        chosen_sections_len += len(text) + 2\n",
    "        if chosen_sections_len > max_section_len:\n",
    "            break\n",
    "        chosen_sections.append(text)\n",
    "    concatenated_doc = separator.join(chosen_sections)\n",
    "    print(\n",
    "        f\"With maximum sequence length {max_section_len}, selected top {len(chosen_sections)} document sections: \\n{concatenated_doc}\"\n",
    "    )\n",
    "    return concatenated_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bb111819-b04c-44e1-831b-f18aac6d9959",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With maximum sequence length 1000, selected top 4 document sections: \n",
      "Managed Spot Training can be used with all instances supported in Amazon SageMaker.\n",
      "Managed Spot Training is supported in all AWS Regions where Amazon SageMaker is currently available.\n",
      "You enable the Managed Spot Training option when submitting your training jobs and you also specify how long you want to wait for Spot capacity. Amazon SageMaker will then use Amazon EC2 Spot instances to run your job and manages the Spot capacity. You have full visibility into the status of your training jobs, both while they are running and while they are waiting for capacity.\n",
      "Managed Spot Training with Amazon SageMaker lets you train your ML models using Amazon EC2 Spot instances, while reducing the cost of training your models by up to 90%.\n"
     ]
    }
   ],
   "source": [
    "context_str = construct_context(contexts=contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c6b400e5-5bed-466e-86c1-d30a0240729b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Input]: Which instances can I use with Managed Spot Training in SageMaker?\n",
      "[Output]: all instances supported in Amazon SageMaker\n"
     ]
    }
   ],
   "source": [
    "text_input = prompt_template.replace(\"{context}\", context_str).replace(\"{question}\", question)\n",
    "\n",
    "out = llm.predict({\"inputs\": text_input})\n",
    "generated_text = out[0][\"generated_text\"]\n",
    "print(f\"[Input]: {question}\\n[Output]: {generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b70f536-dda1-43fd-8246-bcf2bc09965a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:darkblue; color:white; padding:1px; font-size:20px\">\n",
    "Bringing it All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a009a7-75dc-48fe-bd0a-4098ec505b91",
   "metadata": {
    "tags": []
   },
   "source": [
    "The function below brings together the steps outlined in the green path of the project overview.\n",
    "\n",
    "<img src=\"./images/query_overview.png\" width=\"700\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "833e89a6-4e98-407f-98fb-5a568ee57a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag_query(question: str) -> str:\n",
    "    # create query vec\n",
    "    query_vec = embed_docs(question)[0]\n",
    "    # query pinecone\n",
    "    res = index.query(query_vec, top_k=5, include_metadata=True)\n",
    "    # get contexts\n",
    "    contexts = [match.metadata['text'] for match in res.matches]\n",
    "    # build the multiple contexts string\n",
    "    context_str = construct_context(contexts=contexts)\n",
    "    # create our retrieval augmented prompt\n",
    "    text_input = prompt_template.replace(\"{context}\", context_str).replace(\"{question}\", question)\n",
    "    # make prediction\n",
    "    out = llm.predict({\"inputs\": text_input})\n",
    "    return out[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "546aeef2-f85a-4fcb-8e63-4cdf97c1881e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With maximum sequence length 1000, selected top 4 document sections: \n",
      "Managed Spot Training can be used with all instances supported in Amazon SageMaker.\n",
      "Managed Spot Training is supported in all AWS Regions where Amazon SageMaker is currently available.\n",
      "You enable the Managed Spot Training option when submitting your training jobs and you also specify how long you want to wait for Spot capacity. Amazon SageMaker will then use Amazon EC2 Spot instances to run your job and manages the Spot capacity. You have full visibility into the status of your training jobs, both while they are running and while they are waiting for capacity.\n",
      "Managed Spot Training with Amazon SageMaker lets you train your ML models using Amazon EC2 Spot instances, while reducing the cost of training your models by up to 90%.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'all instances supported in Amazon SageMaker'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_query(\"Which instances can I use with Managed Spot Training in SageMaker?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "21d0bd89-2785-40dc-a79a-ff6d3a2bafa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With maximum sequence length 1000, selected top 1 document sections: \n",
      "To get started with AmazonÂ SageMaker Edge Manager, you need to compile and package your trained ML models in the cloud, register your devices, and prepare your devices with the SageMaker Edge Manager SDK. To prepare your model for deployment, SageMaker Edge Manager uses SageMaker Neo to compile your model for your target edge hardware. Once a model is compiled, SageMaker Edge Manager signs the model with an AWS generated key, then packages the model with its runtime and your necessary credentials to get it ready for deployment. On the device side, you register your device with SageMaker Edge Manager, download the SageMaker Edge Manager SDK, and then follow the instructions to install the SageMaker Edge Manager agent on your devices. The tutorial notebook provides a step-by-step example of how you can prepare the models and connect your models on edge devices with SageMaker Edge Manager.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't know\""
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_query(\"How do I create a Hugging Face instance on Sagemaker?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "733a9b1d-2975-475a-9ed0-4c6a9816964c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With maximum sequence length 1000, selected top 5 document sections: \n",
      "Amazon Textract goes beyond simple optical character recognition (OCR) to also identify the contents of fields in forms and information stored in tables\n",
      "Amazon Textract Amazon Textract is a service that automatically extracts text and data from scanned documents\n",
      "Amazon Textract overcomes these challenges by using machine learning to instantly \"read\" virtually any type of document to accurately extract text and data without the need for any manual effort or custom code\n",
      "Many companies today extract data from documents and forms through manual data entry that's slow and expensive or through simple optical character recognition (OCR) software that is difficult to customize\n",
      "Maintain compliance in document archives Because Amazon Textract identifies data types and form labels automatically, it's easy to maintain compliance with information controls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_query(\"Does Amazon textract just do OCR?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6291fee9-2fd2-43ab-b43a-6d0c3cf7d41b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With maximum sequence length 1000, selected top 4 document sections: \n",
      "Amazon Textract Amazon Textract is a service that automatically extracts text and data from scanned documents\n",
      "\" Build automated document processing workflows Amazon Textract can provide the inputs required to automatically process forms without human intervention\n",
      "Amazon Textract overcomes these challenges by using machine learning to instantly \"read\" virtually any type of document to accurately extract text and data without the need for any manual effort or custom code\n",
      "Once a Managed Spot Training job is completed, you can see the savings in the AWS Management Console and also calculate the cost savings as the percentage difference between the duration for which the training job ran and the duration for which you were billed. Regardless of how many times your Managed Spot Training jobs are interrupted, you are charged only once for the duration for which the data was downloaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't know\""
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_query(\"Where did I leave my AWS Textract this morning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0b98fa-d84f-4da8-9847-2cf1fe1bd7ae",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:10px; font-size:20px\">\n",
    "Clean-up Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "32c28278-a87a-4acb-b8a1-39caa20cfc6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete LLM Model Endpoint\n",
    "llm.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "452b5df5-e89d-49cc-9962-5439e4130862",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete Embedding Model Endpoint\n",
    "encoder.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b871993-4db5-48b8-a201-649944ae9a38",
   "metadata": {},
   "source": [
    "You can verify endpoint deletion under 'Inference' -> 'Endpoints' in the SageMaker UI"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
